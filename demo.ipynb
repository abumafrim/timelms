{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing TimeLMs\n",
    "\n",
    "TimeLMs allows for easy access to models continuously trained on social media over regular intervals for researching language model degradation, as well as cultural shifts affecting language usage on social media.\n",
    "\n",
    "In this notebook we'll show to use TimeLMs for two tasks: masked prediction and computing perplexity scores.\n",
    "We show how both tasks can be addressed using different modes:\n",
    "- 'latest', using our most recently trained Twitter model.\n",
    "- 'custom', using a model for a custom date provided by the user.\n",
    "- 'corresponding', using the model that was trained only until to each tweet's date (i.e., its corresponding quarter).\n",
    "- 'quarterly', using all available models trained over time in quarterly intervals.\n",
    "\n",
    "Only the 'corresponding' mode requires the 'created_at' field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Before running this notebook, make sure you create a separate environment for TimeLMs and install dependencies.\n",
    "You may create a new environment using conda and install dependencies following the commands below.\n",
    "We assume you already have PyTorch with CUDA support installed (tested with torch==1.8.2+cu111 and CUDA 11.2).\n",
    "\n",
    "Afterwards, make sure you're using running this notebook using the appropriate kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ conda create -n timelms python=3.7\n",
    "$ conda activate timelms\n",
    "$ pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having setup your environment, you can start using TimeLMs as simply as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timelms import TimeLMs\n",
    "tlms = TimeLMs(device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked Predictions\n",
    "\n",
    "Below we have tweets with a random word replaced with the model's mask token. You may experiment with other sentences or masking positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [{\"text\": \"So glad I'm <mask> vaccinated .\", \"created_at\": \"2021-02-01T23:14:26.000Z\"},\n",
    "          {\"text\": \"I keep forgetting to bring a <mask> .\", \"created_at\": \"2020-01-18T09:22:48.000Z\"},\n",
    "          {\"text\": \"Looking forward to watching <mask> Game tonight !\", \"created_at\": \"2021-10-11T12:34:56.000Z\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_masked_predictions(preds):  # helper function for more readable outputs\n",
    "    for tw in preds:\n",
    "        print(tw['text'])\n",
    "        for model_name in sorted(tw['predictions'].keys(), key=lambda x: tlms.model2date(x)):\n",
    "            print('\\t', model_name.split('-')[-1])\n",
    "            for pred in tw['predictions'][model_name]:\n",
    "                print('\\t\\t', round(pred['score'], 6), pred['token_str'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So glad I'm <mask> vaccinated .\n",
      "\t mar2021\n",
      "\t\t 0.506805  getting\n",
      "\t\t 0.256622  not\n",
      "\t\t 0.073613  fully\n",
      "\n",
      "I keep forgetting to bring a <mask> .\n",
      "\t mar2020\n",
      "\t\t 0.079254  bag\n",
      "\t\t 0.078195  purse\n",
      "\t\t 0.073761  charger\n",
      "\n",
      "Looking forward to watching <mask> Game tonight !\n",
      "\t dec2021\n",
      "\t\t 0.327614  Squid\n",
      "\t\t 0.258569  the\n",
      "\t\t 0.138299  The\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = tlms.get_masked_predictions(tweets, mode='corresponding', top_k=3)\n",
    "\n",
    "print_masked_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So glad I'm <mask> vaccinated .\n",
      "\t dec2021\n",
      "\t\t 0.327812  fully\n",
      "\t\t 0.266009  getting\n",
      "\t\t 0.253695  not\n",
      "\n",
      "I keep forgetting to bring a <mask> .\n",
      "\t dec2021\n",
      "\t\t 0.077349  bag\n",
      "\t\t 0.075191  lighter\n",
      "\t\t 0.065851  charger\n",
      "\n",
      "Looking forward to watching <mask> Game tonight !\n",
      "\t dec2021\n",
      "\t\t 0.327613  Squid\n",
      "\t\t 0.258569  the\n",
      "\t\t 0.138299  The\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = tlms.get_masked_predictions(tweets, mode='latest', top_k=3)\n",
    "\n",
    "print_masked_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So glad I'm <mask> vaccinated .\n",
      "\t mar2020\n",
      "\t\t 0.518831  not\n",
      "\t\t 0.172038  getting\n",
      "\t\t 0.10072  self\n",
      "\t jun2020\n",
      "\t\t 0.486295  not\n",
      "\t\t 0.235272  getting\n",
      "\t\t 0.072481  fully\n",
      "\t sep2020\n",
      "\t\t 0.541163  not\n",
      "\t\t 0.214932  getting\n",
      "\t\t 0.070767  fully\n",
      "\t dec2020\n",
      "\t\t 0.386371  not\n",
      "\t\t 0.298721  getting\n",
      "\t\t 0.100641  fully\n",
      "\t mar2021\n",
      "\t\t 0.506804  getting\n",
      "\t\t 0.256623  not\n",
      "\t\t 0.073613  fully\n",
      "\t jun2021\n",
      "\t\t 0.466774  fully\n",
      "\t\t 0.270858  getting\n",
      "\t\t 0.149782  not\n",
      "\t sep2021\n",
      "\t\t 0.380552  fully\n",
      "\t\t 0.330308  getting\n",
      "\t\t 0.148695  not\n",
      "\t dec2021\n",
      "\t\t 0.327812  fully\n",
      "\t\t 0.266009  getting\n",
      "\t\t 0.253695  not\n",
      "\n",
      "I keep forgetting to bring a <mask> .\n",
      "\t mar2020\n",
      "\t\t 0.079254  bag\n",
      "\t\t 0.078195  purse\n",
      "\t\t 0.073761  charger\n",
      "\t jun2020\n",
      "\t\t 0.075227  mask\n",
      "\t\t 0.064533  bag\n",
      "\t\t 0.05607  purse\n",
      "\t sep2020\n",
      "\t\t 0.104582  mask\n",
      "\t\t 0.077254  bag\n",
      "\t\t 0.064505  purse\n",
      "\t dec2020\n",
      "\t\t 0.10412  bag\n",
      "\t\t 0.095423  purse\n",
      "\t\t 0.071389  charger\n",
      "\t mar2021\n",
      "\t\t 0.085629  purse\n",
      "\t\t 0.083771  charger\n",
      "\t\t 0.081422  bag\n",
      "\t jun2021\n",
      "\t\t 0.096614  bag\n",
      "\t\t 0.064811  charger\n",
      "\t\t 0.055432  lighter\n",
      "\t sep2021\n",
      "\t\t 0.108284  charger\n",
      "\t\t 0.079544  bag\n",
      "\t\t 0.064439  purse\n",
      "\t dec2021\n",
      "\t\t 0.077349  bag\n",
      "\t\t 0.075191  lighter\n",
      "\t\t 0.065851  charger\n",
      "\n",
      "Looking forward to watching <mask> Game tonight !\n",
      "\t mar2020\n",
      "\t\t 0.600626  the\n",
      "\t\t 0.149897  The\n",
      "\t\t 0.054674  this\n",
      "\t jun2020\n",
      "\t\t 0.318902  The\n",
      "\t\t 0.29253  the\n",
      "\t\t 0.219134  End\n",
      "\t sep2020\n",
      "\t\t 0.534695  the\n",
      "\t\t 0.220063  The\n",
      "\t\t 0.060689  End\n",
      "\t dec2020\n",
      "\t\t 0.604814  the\n",
      "\t\t 0.207775  The\n",
      "\t\t 0.029143  End\n",
      "\t mar2021\n",
      "\t\t 0.563788  the\n",
      "\t\t 0.239968  The\n",
      "\t\t 0.048183  End\n",
      "\t jun2021\n",
      "\t\t 0.723476  the\n",
      "\t\t 0.107009  The\n",
      "\t\t 0.031982  this\n",
      "\t sep2021\n",
      "\t\t 0.650989  the\n",
      "\t\t 0.124828  The\n",
      "\t\t 0.027014  this\n",
      "\t dec2021\n",
      "\t\t 0.327613  Squid\n",
      "\t\t 0.258569  the\n",
      "\t\t 0.138299  The\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = tlms.get_masked_predictions(tweets, mode='quarterly', top_k=3)\n",
    "\n",
    "print_masked_predictions(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity Scores\n",
    "\n",
    "Below we have tweets with associated dates (the 'created_at' field, following the Twitter API field name).\n",
    "\n",
    "TimeLMs provides the Pseudo Perplexity (PPPL) score for a set of tweets, and the Pseudo Log Likelihood (PLL) score for individual tweets. If you want to compare the PLL score between different tweets, you should also use the number of subtokens for normalization, provided in the output. For more details about these scores, please see [Salazar et al 2020](https://arxiv.org/abs/1910.14659)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [{'text': 'She is pure heart #SanaTheBBWinner', 'created_at': '2020-02-09T05:55:00.000Z'},\n",
    "          {'text': '@BoredApeYC @user is flipper3.0, Makes Dr. Burry feel like a boomer', 'created_at': '2021-11-11T23:10:00.000Z'},\n",
    "          {'text': 'Looking forward to watching Squid Game tonight !', 'created_at': '2021-10-11T12:34:56.000Z'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pppl(pseudo_ppls, tweets):  # helper function for more readable outputs\n",
    "\n",
    "    print('Pseudo Perplexity Scores (PPPL) for set of tweets:')\n",
    "    for model_name in pseudo_ppls:\n",
    "        print(f\"\\t{model_name.split('-')[-1]}: {round(pseudo_ppls[model_name]['pppl'], 3)}\")\n",
    "    print()\n",
    "\n",
    "    print('Pseudo Log-Likelihood (PLL) by tweet:')\n",
    "    for tw in tweets:\n",
    "        print('\\nTweet:', tw['text'])\n",
    "        for model_name in sorted(tw['scores'].keys(), key=lambda x: tlms.model2date(x)):\n",
    "            print(f\"\\t{model_name.split('-')[-1]}: {round(tw['scores'][model_name], 3)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo Perplexity Scores (PPPL) for set of tweets:\n",
      "\tmar2020: 3.347\n",
      "\tdec2021: 5.664\n",
      "\n",
      "Pseudo Log-Likelihood (PLL) by tweet:\n",
      "\n",
      "Tweet: She is pure heart #SanaTheBBWinner\n",
      "\tmar2020: -14.496\n",
      "\n",
      "\n",
      "Tweet: @BoredApeYC @user is flipper3.0, Makes Dr. Burry feel like a boomer\n",
      "\tdec2021: -53.601\n",
      "\n",
      "\n",
      "Tweet: Looking forward to watching Squid Game tonight !\n",
      "\tdec2021: -10.561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pseudo_ppls = tlms.get_pseudo_ppl(tweets, mode='corresponding')\n",
    "\n",
    "print_pppl(pseudo_ppls, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo Perplexity Scores (PPPL) for set of tweets:\n",
      "\tdec2021: 5.803\n",
      "\n",
      "Pseudo Log-Likelihood (PLL) by tweet:\n",
      "\n",
      "Tweet: She is pure heart #SanaTheBBWinner\n",
      "\tdec2021: -22.0\n",
      "\n",
      "\n",
      "Tweet: @BoredApeYC @user is flipper3.0, Makes Dr. Burry feel like a boomer\n",
      "\tdec2021: -53.601\n",
      "\n",
      "\n",
      "Tweet: Looking forward to watching Squid Game tonight !\n",
      "\tdec2021: -10.561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pseudo_ppls = tlms.get_pseudo_ppl(tweets, mode='latest')\n",
    "\n",
    "print_pppl(pseudo_ppls, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo Perplexity Scores (PPPL) for set of tweets:\n",
      "\tmar2020: 18.762\n",
      "\tjun2020: 20.022\n",
      "\tsep2020: 20.506\n",
      "\tdec2020: 19.295\n",
      "\tmar2021: 19.473\n",
      "\tjun2021: 14.636\n",
      "\tsep2021: 8.346\n",
      "\tdec2021: 5.803\n",
      "\n",
      "Pseudo Log-Likelihood (PLL) by tweet:\n",
      "\n",
      "Tweet: She is pure heart #SanaTheBBWinner\n",
      "\tmar2020: -14.496\n",
      "\tjun2020: -18.785\n",
      "\tsep2020: -20.087\n",
      "\tdec2020: -17.557\n",
      "\tmar2021: -19.363\n",
      "\tjun2021: -21.44\n",
      "\tsep2021: -22.217\n",
      "\tdec2021: -22.0\n",
      "\n",
      "\n",
      "Tweet: @BoredApeYC @user is flipper3.0, Makes Dr. Burry feel like a boomer\n",
      "\tmar2020: -92.476\n",
      "\tjun2020: -91.488\n",
      "\tsep2020: -91.245\n",
      "\tdec2020: -90.408\n",
      "\tmar2021: -89.938\n",
      "\tjun2021: -74.091\n",
      "\tsep2021: -55.696\n",
      "\tdec2021: -53.601\n",
      "\n",
      "\n",
      "Tweet: Looking forward to watching Squid Game tonight !\n",
      "\tmar2020: -36.686\n",
      "\tjun2020: -36.571\n",
      "\tsep2020: -36.683\n",
      "\tdec2020: -37.067\n",
      "\tmar2021: -36.181\n",
      "\tjun2021: -35.961\n",
      "\tsep2021: -26.057\n",
      "\tdec2021: -10.561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pseudo_ppls = tlms.get_pseudo_ppl(tweets, mode='quarterly')\n",
    "\n",
    "print_pppl(pseudo_ppls, tweets)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad8c53c78fef25353f4f47a53ae87e9ffb39508d8f8fbee1854d1e4e84893ced"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('scoring': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
